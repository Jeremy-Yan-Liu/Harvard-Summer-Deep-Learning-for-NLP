{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5.1 - Introduction to convnets\n",
    "\n",
    "This notebook contains the code sample found in Chapter 5, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "----\n",
    "\n",
    "First, let's take a practical look at a very simple convnet example. We will use our convnet to classify MNIST digits, a task that you've already been \n",
    "through in Chapter 2, using a densely-connected network (our test accuracy then was 97.8%). Even though our convnet will be very basic, its \n",
    "accuracy will still blow out of the water that of the densely-connected model from Chapter 2.\n",
    "\n",
    "The 6 lines of code below show you what a basic convnet looks like. It's a stack of `Conv2D` and `MaxPooling2D` layers. We'll see in a \n",
    "minute what they do concretely.\n",
    "Importantly, a convnet takes as input tensors of shape `(image_height, image_width, image_channels)` (not including the batch dimension). \n",
    "In our case, we will configure our convnet to process inputs of size `(28, 28, 1)`, which is the format of MNIST images. We do this via \n",
    "passing the argument `input_shape=(28, 28, 1)` to our first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 23:10:33.324015 4455646656 deprecation_wrapper.py:119] From /anaconda3/envs/pytf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0715 23:10:33.344952 4455646656 deprecation_wrapper.py:119] From /anaconda3/envs/pytf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0715 23:10:33.353614 4455646656 deprecation_wrapper.py:119] From /anaconda3/envs/pytf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0715 23:10:33.371401 4455646656 deprecation_wrapper.py:119] From /anaconda3/envs/pytf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the architecture of our convnet so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can see above that the output of every `Conv2D` and `MaxPooling2D` layer is a 3D tensor of shape `(height, width, channels)`. The width \n",
    "and height dimensions tend to shrink as we go deeper in the network. The number of channels is controlled by the first argument passed to \n",
    "the `Conv2D` layers (e.g. 32 or 64).\n",
    "\n",
    "The next step would be to feed our last output tensor (of shape `(3, 3, 64)`) into a densely-connected classifier network like those you are \n",
    "already familiar with: a stack of `Dense` layers. These classifiers process vectors, which are 1D, whereas our current output is a 3D tensor. \n",
    "So first, we will have to flatten our 3D outputs to 1D, and then add a few `Dense` layers on top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do 10-way classification, so we use a final layer with 10 outputs and a softmax activation. Now here's what our network \n",
    "looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our `(3, 3, 64)` outputs were flattened into vectors of shape `(576,)`, before going through two `Dense` layers.\n",
    "\n",
    "Now, let's train our convnet on the MNIST digits. We will reuse a lot of the code we have already covered in the MNIST example from Chapter \n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.0055 - acc: 0.9990\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.0046 - acc: 0.9993\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.0044 - acc: 0.9992\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0028 - acc: 0.9995\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add two L2 Regularizer with assigned paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def buildL2Model(l):\n",
    "    l2_model = models.Sequential()\n",
    "    l2_model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(l), activation='relu', input_shape=(28, 28, 1)))\n",
    "    l2_model.add(layers.MaxPooling2D((2, 2)))\n",
    "    l2_model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(l), activation='relu'))\n",
    "    l2_model.add(layers.MaxPooling2D((2, 2)))\n",
    "    l2_model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(l), activation='relu'))\n",
    "    l2_model.add(layers.Flatten())\n",
    "    l2_model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(l), activation='relu'))\n",
    "    l2_model.add(layers.Dense(10, kernel_regularizer=regularizers.l2(l), activation='softmax'))\n",
    "\n",
    "    return(l2_model)\n",
    "\n",
    "\n",
    "l2_model_high = buildL2Model(.05)\n",
    "l2_model_low = buildL2Model(.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile L2 Model ( l = .05 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.0164 - acc: 0.9948\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.0136 - acc: 0.9959\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.0099 - acc: 0.9971\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.0095 - acc: 0.9973\n"
     ]
    }
   ],
   "source": [
    "l2_model_high.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_high = model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile L2 Model ( l = .01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.0076 - acc: 0.9979\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.0060 - acc: 0.9981\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.0071 - acc: 0.9983\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.0057 - acc: 0.9986\n"
     ]
    }
   ],
   "source": [
    "l2_model_low.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_low = model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report on Overfitting with Validation Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1447fd828>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1,6)\n",
    "original_loss = history.history['loss']\n",
    "l2_model_high_loss = history_high.history['loss']\n",
    "l2_model_low_loss = history_low.history['loss']\n",
    "\n",
    "plt.plot(epochs, original_loss, 'b+', label='Original model') \n",
    "plt.plot(epochs, l2_model_high_loss, 'bo', label='L2-high-regularized model')\n",
    "plt.plot(epochs, l2_model_low_loss, 'bx', label='L2-low-regularized model') \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No val_loss is reported in the history object, use test_loss/acc instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_high.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 79us/step\n",
      "10000/10000 [==============================] - 1s 71us/step\n",
      "10000/10000 [==============================] - 1s 70us/step\n"
     ]
    }
   ],
   "source": [
    "org_test_loss, org_test_acc = model.evaluate(test_images, test_labels)\n",
    "high_test_loss, high_test_acc = l2_model_high.evaluate(test_images, test_labels)\n",
    "low_test_loss, low_test_acc = l2_model_low.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unregularized</td>\n",
       "      <td>0.080912</td>\n",
       "      <td>0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low-regularized</td>\n",
       "      <td>4.728074</td>\n",
       "      <td>0.1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High-regularized</td>\n",
       "      <td>14.378785</td>\n",
       "      <td>0.1130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Test Loss  Test Accuracy\n",
       "0     Unregularized   0.080912         0.9922\n",
       "1   Low-regularized   4.728074         0.1145\n",
       "2  High-regularized  14.378785         0.1130"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"Model\" : [\"Unregularized\", \"Low-regularized\", \"High-regularized\"],\n",
    "              \"Test Loss\": [org_test_loss, low_test_loss,high_test_loss],\n",
    "              \"Test Accuracy\" : [org_test_acc, low_test_acc, high_test_acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the regularizer parameter gets larger, the training loss grows as epochs and the test loss also increases. Test accuracy also deteriorates, possible due to unoptimized choice of the regularization parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytf",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
